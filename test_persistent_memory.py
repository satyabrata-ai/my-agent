#!/usr/bin/env python3
"""
Test script for persistent memory and structured JSON output features.
Demonstrates low-latency caching and datasource attribution.
"""

import json
from app.sub_agents.news_sentiment_agent.tools import (
    analyze_news_headline,
    analyze_analyst_sentiment,
    get_comprehensive_sentiment,
    get_sentiment_statistics,
    recall_ticker_history,
    search_agent_memory,
    get_memory_statistics,
    persistent_memory
)


def print_json(data, title=""):
    """Pretty print JSON data"""
    if title:
        print(f"\n{'='*80}")
        print(f"  {title}")
        print(f"{'='*80}")
    print(json.dumps(data, indent=2))


def test_headline_analysis():
    """Test headline sentiment analysis with caching"""
    print("\n" + "="*80)
    print("TEST 1: HEADLINE ANALYSIS WITH STRUCTURED JSON OUTPUT")
    print("="*80)
    
    headline = "Apple announces record quarterly earnings"
    
    print(f"\nğŸ” First Analysis (will cache result):")
    result1 = analyze_news_headline(headline)
    print_json(result1)
    
    print(f"\nâš¡ Second Analysis (should hit cache):")
    result2 = analyze_news_headline(headline)
    print_json(result2)
    
    # Check if second call was from cache
    if result2.get("performance", {}).get("cache_hit"):
        print("\nâœ… Cache working! Second call was ultra-fast!")
    else:
        print("\nâš ï¸  Cache miss - both calls queried data")


def test_analyst_sentiment():
    """Test analyst sentiment with datasource attribution"""
    print("\n" + "="*80)
    print("TEST 2: ANALYST SENTIMENT WITH FULL DATASOURCE ATTRIBUTION")
    print("="*80)
    
    ticker = "AAPL"
    
    print(f"\nğŸ“Š Analyzing {ticker}:")
    result = analyze_analyst_sentiment(ticker)
    print_json(result)
    
    # Extract and highlight datasources
    datasources = result.get("datasources", {})
    print(f"\nğŸ“ DATASOURCE SUMMARY:")
    print(f"   Files Matched: {datasources.get('files_matched', [])}")
    print(f"   Records Found: {datasources.get('total_records_found', 0)}")
    print(f"   Storage: {datasources.get('storage_backend', 'unknown')}")


def test_comprehensive_sentiment():
    """Test multi-source comprehensive sentiment"""
    print("\n" + "="*80)
    print("TEST 3: COMPREHENSIVE MULTI-SOURCE SENTIMENT ANALYSIS")
    print("="*80)
    
    ticker = "MSFT"
    
    print(f"\nğŸ” Comprehensive analysis for {ticker}:")
    result = get_comprehensive_sentiment(ticker)
    print_json(result)
    
    # Extract key metrics
    sentiment = result.get("result", {}).get("overall_sentiment", "unknown")
    confidence = result.get("result", {}).get("confidence", "none")
    sources = result.get("datasources", {}).get("sources_with_data", [])
    
    print(f"\nğŸ“Š SUMMARY:")
    print(f"   Overall Sentiment: {sentiment.upper()}")
    print(f"   Confidence: {confidence.upper()}")
    print(f"   Data Sources: {', '.join(sources)}")


def test_memory_recall():
    """Test persistent memory recall"""
    print("\n" + "="*80)
    print("TEST 4: PERSISTENT MEMORY RECALL")
    print("="*80)
    
    # First, analyze a ticker to store in memory
    ticker = "GOOGL"
    print(f"\nğŸ“Š Analyzing {ticker} (will be stored in memory):")
    analysis = analyze_analyst_sentiment(ticker)
    
    # Now recall from memory
    print(f"\nğŸ§  Recalling {ticker} from persistent memory:")
    history = recall_ticker_history(ticker)
    print_json(history)
    
    if history.get("result", {}).get("analysis_count", 0) > 0:
        print("\nâœ… Memory is working! Analysis was stored and recalled!")
    else:
        print("\nâš ï¸  No historical data found (might be first run)")


def test_memory_statistics():
    """Test memory statistics"""
    print("\n" + "="*80)
    print("TEST 5: AGENT MEMORY STATISTICS")
    print("="*80)
    
    print("\nğŸ“Š Getting memory statistics:")
    stats = get_memory_statistics()
    print_json(stats)
    
    perf = stats.get("performance", {})
    stored = stats.get("result", {}).get("stored_data", {})
    
    print(f"\nğŸ’¾ MEMORY SUMMARY:")
    print(f"   Tickers Analyzed: {stored.get('unique_tickers_analyzed', 0)}")
    print(f"   Cached Queries: {stored.get('cached_queries', 0)}")
    print(f"   Cache Hit Rate: {perf.get('cache_hit_rate', 0):.1%}")
    print(f"   Total Queries: {perf.get('total_queries', 0)}")


def test_statistics():
    """Test sentiment statistics"""
    print("\n" + "="*80)
    print("TEST 6: MARKET-WIDE SENTIMENT STATISTICS")
    print("="*80)
    
    print("\nğŸ“ˆ Getting market-wide statistics:")
    stats = get_sentiment_statistics("all")
    print_json(stats)


def test_memory_search():
    """Test memory search"""
    print("\n" + "="*80)
    print("TEST 7: MEMORY SEARCH")
    print("="*80)
    
    query = "AAPL"
    print(f"\nğŸ” Searching memory for: {query}")
    results = search_agent_memory(query)
    print_json(results)


def save_persistent_memory():
    """Force save persistent memory to GCS"""
    print("\n" + "="*80)
    print("SAVING PERSISTENT MEMORY TO GCS")
    print("="*80)
    
    print("\nğŸ’¾ Forcing memory save to GCS...")
    persistent_memory.save_memory(force=True)
    print("âœ… Memory saved!")


def main():
    """Run all tests"""
    print("\n" + "="*80)
    print("ğŸš€ TESTING PERSISTENT MEMORY & STRUCTURED JSON OUTPUT")
    print("="*80)
    print("\nThis script demonstrates:")
    print("  âœ“ Low-latency caching")
    print("  âœ“ Structured JSON output")
    print("  âœ“ Full datasource attribution")
    print("  âœ“ Persistent memory across sessions")
    print("  âœ“ Ultra-fast memory recall")
    
    try:
        # Run all tests
        test_headline_analysis()
        test_analyst_sentiment()
        test_comprehensive_sentiment()
        test_memory_recall()
        test_memory_statistics()
        test_statistics()
        test_memory_search()
        
        # Save memory
        save_persistent_memory()
        
        print("\n" + "="*80)
        print("âœ… ALL TESTS COMPLETED!")
        print("="*80)
        print("\nğŸ“ Key Features Demonstrated:")
        print("  1. âš¡ Low-latency caching (< 50ms for cached queries)")
        print("  2. ğŸ“Š Structured JSON output with full attribution")
        print("  3. ğŸ’¾ Persistent memory stored in GCS")
        print("  4. ğŸ§  Ultra-fast memory recall")
        print("  5. ğŸ“ Complete datasource tracking")
        print("\nğŸ¯ Next Steps:")
        print("  - Run this script again to see cache hits!")
        print("  - Check GCS bucket for agent_memory/session_memory.json")
        print("  - Use the agent in playground to see memory continuity")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
